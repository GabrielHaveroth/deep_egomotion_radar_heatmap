{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "heamap_imu_cross_att.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyNfdGj0iZ9ggdfQM/fTPYZR",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/GabrielHaveroth/deep_egomotion_radar_heatmap/blob/main/heamap_imu_cross_att.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jJ4pt0HVS9zJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "991cbf93-9a13-40ae-d452-f5ff5d9b9a8f"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "95zSs73LUki8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4a4e0059-c8e5-49a1-c28b-1fab049ca78f"
      },
      "source": [
        "!cd drive\n",
        "!ls"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "drive  sample_data\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J1gy-MD6b9m-"
      },
      "source": [
        "# Loading dataset\n",
        "# import numpy as np\n",
        "# y = np.load('/content/drive/My Drive/Mestrado/Coloradar/data/delta_poses.npy')\n",
        "# heatmaps = np.load('/content/drive/My Drive/Mestrado/Coloradar/data/heatmap.npy')\n",
        "# imu_data = np.load('/content/drive/My Drive/Mestrado/Coloradar/data/imu.npy')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rTeXxMG9VkD6",
        "outputId": "611ddaf8-b8e6-4668-e7f4-bbef7b33f381"
      },
      "source": [
        "%cd /content/drive/My Drive/Mestrado/Coloradar/data\n",
        "%ls"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/My Drive/Mestrado/Coloradar/data\n",
            "delta_poses.npy  imu.npy  \u001b[0m\u001b[01;34mmodels\u001b[0m/          val.tfrecords\n",
            "heatmap.npy      \u001b[01;34mlogs\u001b[0m/    train.tfrecords\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JsfPLdYBx2Ts"
      },
      "source": [
        "# tf record helpers\n",
        "import tensorflow as tf\n",
        "AUTOTUNE = tf.data.AUTOTUNE\n",
        "BATCH_SIZE = 16\n",
        "EPOCHS = 100\n",
        "\n",
        "# MAX and MIN POWER\n",
        "MAX_POWER = 4815355.5\n",
        "MIN_POWER = 0.01419168058782816\n",
        "MAX_DOPPLER = 1.1527502536773682\n",
        "MIN_DOPPLER = -1.317428708076477\n",
        "\n",
        "def decode_heatmap(hm_bytes):\n",
        "    frame_vals = tf.io.decode_raw(hm_bytes, little_endian=True, out_type=tf.float32)\n",
        "    frame = tf.reshape(frame_vals, (32, 128, 128, 2))[:, :, :, 0]\n",
        "    return frame\n",
        "\n",
        "def read_tfrecord(example):\n",
        "    feature_description = {'heatmap1': tf.io.FixedLenFeature([], tf.string),\n",
        "                           'heatmap2': tf.io.FixedLenFeature([], tf.string),\n",
        "                           'delta_roll': tf.io.FixedLenFeature([], tf.float32),\n",
        "                           'delta_pitch': tf.io.FixedLenFeature([], tf.float32),\n",
        "                           'delta_yaw': tf.io.FixedLenFeature([], tf.float32),\n",
        "                           'delta_x': tf.io.FixedLenFeature([], tf.float32),\n",
        "                           'delta_y': tf.io.FixedLenFeature([], tf.float32),\n",
        "                           'delta_z': tf.io.FixedLenFeature([], tf.float32)}\n",
        "    example = tf.io.parse_single_example(example, feature_description)\n",
        "    hm1 = (tf.reshape(decode_heatmap(example[\"heatmap1\"]), ((32, 128, 128, 1))) - MIN_POWER) / (MAX_POWER - MIN_POWER)\n",
        "    hm2 = (tf.reshape(decode_heatmap(example[\"heatmap2\"]), ((32, 128, 128, 1))) - MIN_POWER) / (MAX_POWER - MIN_POWER)\n",
        "    hm12 = tf.concat([hm1, hm2], -1)\n",
        "    y_rot = tf.stack([example['delta_roll'], example['delta_pitch'], example['delta_yaw']])\n",
        "    y_trans = tf.stack([example['delta_x'], example['delta_y'], example['delta_z']])\n",
        "    return hm12, (y_trans, y_rot)\n",
        "\n",
        "def load_dataset(filenames):\n",
        "  ignore_order = tf.data.Options()\n",
        "  ignore_order.experimental_deterministic = False  # disable order, increase speed\n",
        "  dataset = tf.data.TFRecordDataset(filenames)  # automatically interleaves reads from multiple files\n",
        "  dataset = dataset.with_options(ignore_order)  # uses data as soon as it streams in, rather than in its original order\n",
        "  dataset = dataset.shuffle(256)\n",
        "  dataset = dataset.map(read_tfrecord, num_parallel_calls=AUTOTUNE)\n",
        "  # returns a dataset of (image, label) pairs if labeled=True or just images if labeled=False\n",
        "  return dataset\n",
        "\n",
        "def get_dataset(filenames):\n",
        "    dataset = load_dataset(filenames)\n",
        "    # dataset = dataset.cache()\n",
        "    # dataset = dataset.repeat()\n",
        "    dataset = dataset.batch(BATCH_SIZE)\n",
        "    dataset = dataset.prefetch(AUTOTUNE)\n",
        "    return dataset\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xcet7cPUyEzQ"
      },
      "source": [
        "# Loading dataset\n",
        "train_dataset = get_dataset('train.tfrecords')\n",
        "val_dataset = get_dataset('val.tfrecords')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 217
        },
        "id": "VBCbNkkmUZCa",
        "outputId": "bee621db-e9ec-494d-d536-eb4d6f44f74a"
      },
      "source": [
        "heatmaps.shape\n",
        "import matplotlib.pyplot as plt\n",
        "plt.imshow(heatmaps[9, :, :, 0])\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-7-48c03ce66a9b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mheatmaps\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mheatmaps\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m9\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'heatmaps' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xnqpPNXPh0Cj",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        },
        "outputId": "63cfbfc2-c15d-452e-cde8-e90082fe24bd"
      },
      "source": [
        "# Split data\n",
        "# from sklearn.model_selection import train_test_split\n",
        "# heatmaps_train, heatmaps_val, imu_data_train, imu_data_val, y_train, y_val = train_test_split(heatmaps, imu_data, y, test_size=0.1, random_state=42)\n",
        "# y_rot_val = y_val[:, 0:3]\n",
        "# y_rot_train = y_train[:, 0:3]\n",
        "# y_trans_val = y_val[:, 3:]\n",
        "# y_trans_train = y_train[:, 3:]\n",
        "# y_train = [y_trans_train, y_rot_train]\n",
        "# y_val = [y_trans_val, y_rot_val]\n",
        "# X_train = [heatmaps_train, imu_data_train]\n",
        "# X_val = [heatmaps_val, imu_data_val]\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-2ee3eb686870>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Split data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_selection\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mheatmaps_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheatmaps_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimu_data_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimu_data_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_val\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mheatmaps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimu_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m42\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0my_rot_val\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my_val\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0my_rot_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'heatmaps' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QszNaF2xkKo1"
      },
      "source": [
        "# Define models\n",
        "from tensorflow.keras import layers, Input, activations, Model\n",
        "\n",
        "def build_sparse_features_regressor(input: Input) -> layers.Flatten:\n",
        "    conv_1 = layers.Conv3D(name='conv1', filters=32, kernel_size=3, strides=1,\n",
        "                           padding='same', activation=activations.relu)(input)\n",
        "    conv_2 = layers.Conv3D(name='conv2', filters=32, kernel_size=3, strides=2,\n",
        "                           padding='same', activation=activations.relu)(conv_1)\n",
        "    pool_1 = layers.MaxPool3D(name=\"pool1\", strides=2)(conv_2)\n",
        "    conv_3 = layers.Conv3D(name='conv3', filters=64, kernel_size=3, strides=2,\n",
        "                           padding='same', activation=activations.relu)(pool_1)\n",
        "    conv_3_1 = layers.Conv3D(name='conv3_1', filters=64, kernel_size=3,\n",
        "                             strides=1, padding='same', activation=activations.relu)(conv_3)\n",
        "    pool_2 = layers.MaxPool3D(name=\"pool2\", strides=2)(conv_3_1)\n",
        "    conv_4 = layers.Conv3D(name='conv4', filters=128, kernel_size=3, strides=2,\n",
        "                           padding='same', activation=activations.relu)(pool_2)\n",
        "    conv_4_1 = layers.Conv3D(name='conv4_1', filters=128, kernel_size=3,\n",
        "                             strides=1, padding='same', activation=activations.relu)(conv_4)\n",
        "\n",
        "    heatmap_features = layers.Flatten()(conv_4_1)\n",
        "\n",
        "       # Translation regressor\n",
        "    fc_trans = layers.Dense(2048, activation='relu')(heatmap_features)  # tanh\n",
        "    fc_trans = layers.Dropout(0.50)(fc_trans)\n",
        "    fc_trans = layers.Dense(2048, activation='relu')(fc_trans)\n",
        "    fc_trans = layers.Dense(3, activation='linear', name='fc_trans')(fc_trans)\n",
        "    # Rotation regressor\n",
        "    fc_rot = layers.Dense(2048, activation='relu')(heatmap_features)  # tanh\n",
        "    fc_rot = layers.Dropout(0.50)(fc_rot)\n",
        "    fc_rot = layers.Dense(2048, activation='relu')(fc_rot)\n",
        "    fc_rot = layers.Dense(3, activation='linear', name='fc_rot')(fc_rot)\n",
        "    model = Model(inputs=input, outputs=[fc_trans, fc_rot])\n",
        "    return model\n",
        "    \n",
        "# Flownet\n",
        "def build_2D_flownet(input: Input, flatten=True):\n",
        "    conv_1 = layers.Conv2D(name='conv1', filters=64, kernel_size=7, strides=2,\n",
        "                           padding='same', activation=activations.relu)(input)\n",
        "    conv_2 = layers.Conv2D(name='conv2', filters=128, kernel_size=5, strides=2,\n",
        "                           padding='same', activation=activations.relu)(conv_1)\n",
        "    conv_3 = layers.Conv2D(name='conv3', filters=256, kernel_size=5, strides=2,\n",
        "                           padding='same', activation=activations.relu)(conv_2)\n",
        "    conv_3_1 = layers.Conv2D(name='conv3_1', filters=256, kernel_size=3,\n",
        "                             strides=1, padding='same', activation=activations.relu)(conv_3)\n",
        "    conv_4 = layers.Conv2D(name='conv4', filters=512, kernel_size=3, strides=2,\n",
        "                           padding='same', activation=activations.relu)(conv_3_1)\n",
        "    conv_4_1 = layers.Conv2D(name='conv4_1', filters=512, kernel_size=3,\n",
        "                             strides=1, padding='same', activation=activations.relu)(conv_4)\n",
        "    conv_5 = layers.Conv2D(name='conv5', filters=512, kernel_size=3, strides=2,\n",
        "                           padding='same', activation=activations.relu)(conv_4_1)\n",
        "    conv_5_1 = layers.Conv2D(name='conv5_1', filters=512, kernel_size=3,\n",
        "                             strides=1, padding='same', activation=activations.relu)(conv_5)\n",
        "    conv_6 = layers.Conv2D(name='conv6', filters=1024, kernel_size=3, strides=2,\n",
        "                           padding='same', activation=activations.relu)(conv_5_1)\n",
        "    conv_6_1 = layers.Conv2D(name='conv6_1', filters=1024, kernel_size=3,\n",
        "                             strides=1, padding='same', activation=activations.relu)(conv_6)\n",
        "    if flatten:\n",
        "        flow2D_features = layers.Flatten()(conv_6_1)\n",
        "    else:\n",
        "        flow2D_features = conv_6_1\n",
        "\n",
        "    return flow2D_features\n",
        "\n",
        "  # Build CROSS-attentive multi-modal odom with IMU always used\n",
        "def build_model_cross_att(imu_length, input_heatmap, mask_att='sigmoid', istraining=True, write_mask=False):\n",
        "    # --- panoramic image data\n",
        "    net = build_2D_flownet(input_heatmap, flatten=False)\n",
        "\n",
        "    # generate the mask for visual features\n",
        "    visual_mask = layers.GlobalAveragePooling2D()(net) # reshape to (?, 1, 1024), 1 stands for timeDistr.\n",
        "    visual_mask = layers.Dense(int(1024/256), activation='relu', use_bias=False, name='visual_mask_relu')(visual_mask)\n",
        "    visual_mask = layers.Dense(1024, activation='sigmoid', use_bias=False, name='visual_mask_sigmoid')(visual_mask)\n",
        "    visual_mask = layers.Reshape((1, 1, 1, 1024))(visual_mask)\n",
        "\n",
        "    # activate mask by element-wise multiplication\n",
        "    visual_att_fea = layers.Multiply()([net, visual_mask])\n",
        "    visual_att_fea = layers.Flatten()(visual_att_fea)\n",
        "\n",
        "    # IMU data\n",
        "    imu_data = Input(shape=(imu_length, 6), name='imu_data')\n",
        "    imu_lstm_1 = layers.LSTM(128, return_sequences=True, name='imu_lstm_1')(imu_data)  # 128, 256\n",
        "\n",
        "    # channel-wise IMU attention\n",
        "    reshape_imu = layers.Reshape((1, imu_length * 128))(imu_lstm_1)  # 2560, 5120, 10240\n",
        "    imu_mask = layers.Dense(128, activation='relu', use_bias=False, name='imu_mask_relu')(reshape_imu)\n",
        "    imu_mask = layers.Dense(imu_length * 128, activation='sigmoid', use_bias=False, name='imu_mask_sigmoid')(imu_mask)\n",
        "    imu_att_fea = layers.Multiply()([reshape_imu, imu_mask])\n",
        "\n",
        "    # cross-modal attention\n",
        "    imu4visual_mask = layers.Dense(128, activation='relu', use_bias=False, name='imu4visual_mask_relu')(imu_att_fea)\n",
        "    imu4visual_mask = layers.Dense(4096, activation=mask_att, use_bias=False, name='imu4visual_mask_sigmoid')(imu4visual_mask)\n",
        "    cross_visual_fea = layers.Multiply()([visual_att_fea, imu4visual_mask, visual_att_fea])\n",
        "\n",
        "    visual4imu_mask = layers.Dense(128, activation='relu', use_bias=False, name='visual4imu_mask_relu')(visual_att_fea)\n",
        "    visual4imu_mask = layers.Dense(imu_length * 128, activation=mask_att, use_bias=False, name='visual4imu_mask_sigmoid')(visual4imu_mask)\n",
        "    cross_imu_fea = layers.Multiply()([imu_att_fea, visual4imu_mask])\n",
        "\n",
        "    # Standard merge feature\n",
        "    merge_features = layers.concatenate([cross_visual_fea, cross_imu_fea], axis=-1)\n",
        "\n",
        "    # Selective features\n",
        "    forward_lstm_1 = layers.LSTM(512, dropout=0.25, return_sequences=True, name='forward_lstm_1')(merge_features)  # dropout_W=0.2, dropout_U=0.2\n",
        "    forward_lstm_2 = layers.LSTM(512, return_sequences=True, name='forward_lstm_2')(forward_lstm_1)\n",
        "\n",
        "    fc_position_1 = layers.Dense(128, activation='relu', name='fc_position_1')(forward_lstm_2)  # tanh\n",
        "    dropout_pos_1 = layers.Dropout(0.5, name='dropout_pos_1')(fc_position_1)\n",
        "    fc_position_2 = layers.Dense(64, activation='relu', name='fc_position_2')(dropout_pos_1)  # tanh\n",
        "    fc_trans = layers.Dense(3, name='fc_trans')(fc_position_2)\n",
        "\n",
        "    fc_orientation_1 = layers.Dense(128, activation='relu', name='fc_orientation_1')(forward_lstm_2)  # tanh\n",
        "    dropout_orientation_1 = layers.Dropout(0.5, name='dropout_wpqr_1')(fc_orientation_1)\n",
        "    fc_orientation_2 = layers.Dense(64, activation='relu', name='fc_orientation_2')(dropout_orientation_1)  # tanh\n",
        "    fc_rot = layers.Dense(3, name='fc_rot')(fc_orientation_2)\n",
        "\n",
        "    model = Model(inputs=[input_heatmap, imu_data], outputs=[fc_trans, fc_rot])\n",
        "\n",
        "    return model\n",
        "  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "HsVHhs5ek-vE",
        "outputId": "017442ab-4a74-437d-f31e-679ecaff6993"
      },
      "source": [
        "# Creating model\n",
        "from tensorflow.keras.optimizers import RMSprop, Adam\n",
        "from tensorflow.keras.callbacks import LearningRateScheduler, ModelCheckpoint, TensorBoard\n",
        "from tensorflow.keras import Input\n",
        "import datetime\n",
        "import os\n",
        "import math\n",
        "\n",
        "def step_decay(epoch):\n",
        "    initial_lrate = 0.0001\n",
        "    drop = 0.75\n",
        "    epochs_drop = 10\n",
        "    lrate = initial_lrate * math.pow(drop,\n",
        "                                     math.floor((1 + epoch) / epochs_drop))\n",
        "    print('Learning rate: ' + str(lrate))\n",
        "    return lrate\n",
        "\n",
        "# Creating checkpoint to save the best model\n",
        "MODELS_FOLDER = './models'\n",
        "checkpoint_folder = os.path.sep.join([MODELS_FOLDER, \"{epoch:03d}-{val_loss:.4f}.hdf5\"])\n",
        "if os.path.exists(checkpoint_folder):\n",
        "    os.remove(checkpoint_folder)\n",
        "checkpointer = ModelCheckpoint(filepath=checkpoint_folder, monitor='val_loss',\n",
        "                               mode='min', save_best_only=True, verbose=1)\n",
        "# Creating tensorboard to realtime evaluate the model\n",
        "log_dir = \"logs/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
        "tensorboard_callback = TensorBoard(log_dir=log_dir, histogram_freq=1, update_freq='batch')\n",
        "# Create a learning rate schedule\n",
        "lrate = LearningRateScheduler(step_decay)\n",
        "# input_shape = (128, 128, 2)\n",
        "input_shape = (32, 128, 128, 2)\n",
        "input = Input(input_shape)\n",
        "# model = build_model_cross_att(40, input)\n",
        "model = build_sparse_features_regressor(input)\n",
        "model.summary()\n",
        "loss_weights = {'fc_trans': 1,'fc_rot': 0.1}\n",
        "adam_opt = Adam(learning_rate=0.0001)\n",
        "model.compile(optimizer=adam_opt, loss={'fc_trans': 'mse', 'fc_rot': 'mse'}, loss_weights=loss_weights)\n",
        "# model.set_weights(weights)\n",
        "# history_model = model.fit(X_train, y_train, validation_data=[X_val, y_val], epochs=200, batch_size=8, callbacks=[lrate, checkpointer, tensorboard_callback], verbose=1)\n",
        "model.fit(train_dataset, validation_data=val_dataset, epochs=100, callbacks=[checkpointer, tensorboard_callback], verbose=1)\n",
        "pickle.dump(history_model, history_file)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_2 (InputLayer)           [(None, 32, 128, 12  0           []                               \n",
            "                                8, 2)]                                                            \n",
            "                                                                                                  \n",
            " conv1 (Conv3D)                 (None, 32, 128, 128  1760        ['input_2[0][0]']                \n",
            "                                , 32)                                                             \n",
            "                                                                                                  \n",
            " conv2 (Conv3D)                 (None, 16, 64, 64,   27680       ['conv1[0][0]']                  \n",
            "                                32)                                                               \n",
            "                                                                                                  \n",
            " pool1 (MaxPooling3D)           (None, 8, 32, 32, 3  0           ['conv2[0][0]']                  \n",
            "                                2)                                                                \n",
            "                                                                                                  \n",
            " conv3 (Conv3D)                 (None, 4, 16, 16, 6  55360       ['pool1[0][0]']                  \n",
            "                                4)                                                                \n",
            "                                                                                                  \n",
            " conv3_1 (Conv3D)               (None, 4, 16, 16, 6  110656      ['conv3[0][0]']                  \n",
            "                                4)                                                                \n",
            "                                                                                                  \n",
            " pool2 (MaxPooling3D)           (None, 2, 8, 8, 64)  0           ['conv3_1[0][0]']                \n",
            "                                                                                                  \n",
            " conv4 (Conv3D)                 (None, 1, 4, 4, 128  221312      ['pool2[0][0]']                  \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv4_1 (Conv3D)               (None, 1, 4, 4, 128  442496      ['conv4[0][0]']                  \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " flatten (Flatten)              (None, 2048)         0           ['conv4_1[0][0]']                \n",
            "                                                                                                  \n",
            " dense (Dense)                  (None, 2048)         4196352     ['flatten[0][0]']                \n",
            "                                                                                                  \n",
            " dense_2 (Dense)                (None, 2048)         4196352     ['flatten[0][0]']                \n",
            "                                                                                                  \n",
            " dropout (Dropout)              (None, 2048)         0           ['dense[0][0]']                  \n",
            "                                                                                                  \n",
            " dropout_1 (Dropout)            (None, 2048)         0           ['dense_2[0][0]']                \n",
            "                                                                                                  \n",
            " dense_1 (Dense)                (None, 2048)         4196352     ['dropout[0][0]']                \n",
            "                                                                                                  \n",
            " dense_3 (Dense)                (None, 2048)         4196352     ['dropout_1[0][0]']              \n",
            "                                                                                                  \n",
            " fc_trans (Dense)               (None, 3)            6147        ['dense_1[0][0]']                \n",
            "                                                                                                  \n",
            " fc_rot (Dense)                 (None, 3)            6147        ['dense_3[0][0]']                \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 17,656,966\n",
            "Trainable params: 17,656,966\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "Epoch 1/100\n",
            "    132/Unknown - 217s 1s/step - loss: 0.0569 - fc_trans_loss: 0.0526 - fc_rot_loss: 0.0436\n",
            "Epoch 00001: val_loss improved from inf to 0.01735, saving model to ./models/001-0.0174.hdf5\n",
            "132/132 [==============================] - 242s 2s/step - loss: 0.0569 - fc_trans_loss: 0.0526 - fc_rot_loss: 0.0436 - val_loss: 0.0174 - val_fc_trans_loss: 0.0163 - val_fc_rot_loss: 0.0106\n",
            "Epoch 2/100\n",
            "132/132 [==============================] - ETA: 0s - loss: 0.0174 - fc_trans_loss: 0.0163 - fc_rot_loss: 0.0107\n",
            "Epoch 00002: val_loss did not improve from 0.01735\n",
            "132/132 [==============================] - 208s 1s/step - loss: 0.0174 - fc_trans_loss: 0.0163 - fc_rot_loss: 0.0107 - val_loss: 0.0174 - val_fc_trans_loss: 0.0163 - val_fc_rot_loss: 0.0106\n",
            "Epoch 3/100\n",
            "132/132 [==============================] - ETA: 0s - loss: 0.0154 - fc_trans_loss: 0.0143 - fc_rot_loss: 0.0110\n",
            "Epoch 00003: val_loss improved from 0.01735 to 0.01302, saving model to ./models/003-0.0130.hdf5\n",
            "132/132 [==============================] - 218s 1s/step - loss: 0.0154 - fc_trans_loss: 0.0143 - fc_rot_loss: 0.0110 - val_loss: 0.0130 - val_fc_trans_loss: 0.0119 - val_fc_rot_loss: 0.0114\n",
            "Epoch 4/100\n",
            "132/132 [==============================] - ETA: 0s - loss: 0.0116 - fc_trans_loss: 0.0105 - fc_rot_loss: 0.0111\n",
            "Epoch 00004: val_loss improved from 0.01302 to 0.01229, saving model to ./models/004-0.0123.hdf5\n",
            "132/132 [==============================] - 216s 1s/step - loss: 0.0116 - fc_trans_loss: 0.0105 - fc_rot_loss: 0.0111 - val_loss: 0.0123 - val_fc_trans_loss: 0.0112 - val_fc_rot_loss: 0.0107\n",
            "Epoch 5/100\n",
            "132/132 [==============================] - ETA: 0s - loss: 0.0108 - fc_trans_loss: 0.0098 - fc_rot_loss: 0.0109\n",
            "Epoch 00005: val_loss improved from 0.01229 to 0.01117, saving model to ./models/005-0.0112.hdf5\n",
            "132/132 [==============================] - 216s 1s/step - loss: 0.0108 - fc_trans_loss: 0.0098 - fc_rot_loss: 0.0109 - val_loss: 0.0112 - val_fc_trans_loss: 0.0101 - val_fc_rot_loss: 0.0107\n",
            "Epoch 6/100\n",
            "132/132 [==============================] - ETA: 0s - loss: 0.0103 - fc_trans_loss: 0.0092 - fc_rot_loss: 0.0112\n",
            "Epoch 00006: val_loss improved from 0.01117 to 0.01105, saving model to ./models/006-0.0111.hdf5\n",
            "132/132 [==============================] - 216s 1s/step - loss: 0.0103 - fc_trans_loss: 0.0092 - fc_rot_loss: 0.0112 - val_loss: 0.0111 - val_fc_trans_loss: 0.0100 - val_fc_rot_loss: 0.0105\n",
            "Epoch 7/100\n",
            "132/132 [==============================] - ETA: 0s - loss: 0.0095 - fc_trans_loss: 0.0084 - fc_rot_loss: 0.0108\n",
            "Epoch 00007: val_loss improved from 0.01105 to 0.00979, saving model to ./models/007-0.0098.hdf5\n",
            "132/132 [==============================] - 216s 1s/step - loss: 0.0095 - fc_trans_loss: 0.0084 - fc_rot_loss: 0.0108 - val_loss: 0.0098 - val_fc_trans_loss: 0.0085 - val_fc_rot_loss: 0.0124\n",
            "Epoch 8/100\n",
            "132/132 [==============================] - ETA: 0s - loss: 0.0090 - fc_trans_loss: 0.0079 - fc_rot_loss: 0.0107\n",
            "Epoch 00008: val_loss improved from 0.00979 to 0.00887, saving model to ./models/008-0.0089.hdf5\n",
            "132/132 [==============================] - 216s 1s/step - loss: 0.0090 - fc_trans_loss: 0.0079 - fc_rot_loss: 0.0107 - val_loss: 0.0089 - val_fc_trans_loss: 0.0078 - val_fc_rot_loss: 0.0105\n",
            "Epoch 9/100\n",
            "132/132 [==============================] - ETA: 0s - loss: 0.0084 - fc_trans_loss: 0.0073 - fc_rot_loss: 0.0107\n",
            "Epoch 00009: val_loss improved from 0.00887 to 0.00842, saving model to ./models/009-0.0084.hdf5\n",
            "132/132 [==============================] - 216s 1s/step - loss: 0.0084 - fc_trans_loss: 0.0073 - fc_rot_loss: 0.0107 - val_loss: 0.0084 - val_fc_trans_loss: 0.0073 - val_fc_rot_loss: 0.0107\n",
            "Epoch 10/100\n",
            "132/132 [==============================] - ETA: 0s - loss: 0.0079 - fc_trans_loss: 0.0068 - fc_rot_loss: 0.0106\n",
            "Epoch 00010: val_loss improved from 0.00842 to 0.00746, saving model to ./models/010-0.0075.hdf5\n",
            "132/132 [==============================] - 216s 1s/step - loss: 0.0079 - fc_trans_loss: 0.0068 - fc_rot_loss: 0.0106 - val_loss: 0.0075 - val_fc_trans_loss: 0.0064 - val_fc_rot_loss: 0.0104\n",
            "Epoch 11/100\n",
            "132/132 [==============================] - ETA: 0s - loss: 0.0074 - fc_trans_loss: 0.0063 - fc_rot_loss: 0.0105\n",
            "Epoch 00011: val_loss improved from 0.00746 to 0.00729, saving model to ./models/011-0.0073.hdf5\n",
            "132/132 [==============================] - 216s 1s/step - loss: 0.0074 - fc_trans_loss: 0.0063 - fc_rot_loss: 0.0105 - val_loss: 0.0073 - val_fc_trans_loss: 0.0062 - val_fc_rot_loss: 0.0104\n",
            "Epoch 12/100\n",
            "132/132 [==============================] - ETA: 0s - loss: 0.0067 - fc_trans_loss: 0.0057 - fc_rot_loss: 0.0102\n",
            "Epoch 00012: val_loss improved from 0.00729 to 0.00691, saving model to ./models/012-0.0069.hdf5\n",
            "132/132 [==============================] - 216s 1s/step - loss: 0.0067 - fc_trans_loss: 0.0057 - fc_rot_loss: 0.0102 - val_loss: 0.0069 - val_fc_trans_loss: 0.0059 - val_fc_rot_loss: 0.0099\n",
            "Epoch 13/100\n",
            "132/132 [==============================] - ETA: 0s - loss: 0.0066 - fc_trans_loss: 0.0056 - fc_rot_loss: 0.0102\n",
            "Epoch 00013: val_loss improved from 0.00691 to 0.00667, saving model to ./models/013-0.0067.hdf5\n",
            "132/132 [==============================] - 216s 1s/step - loss: 0.0066 - fc_trans_loss: 0.0056 - fc_rot_loss: 0.0102 - val_loss: 0.0067 - val_fc_trans_loss: 0.0057 - val_fc_rot_loss: 0.0099\n",
            "Epoch 14/100\n",
            "132/132 [==============================] - ETA: 0s - loss: 0.0062 - fc_trans_loss: 0.0052 - fc_rot_loss: 0.0100\n",
            "Epoch 00014: val_loss did not improve from 0.00667\n",
            "132/132 [==============================] - 216s 1s/step - loss: 0.0062 - fc_trans_loss: 0.0052 - fc_rot_loss: 0.0100 - val_loss: 0.0067 - val_fc_trans_loss: 0.0057 - val_fc_rot_loss: 0.0101\n",
            "Epoch 15/100\n",
            "132/132 [==============================] - ETA: 0s - loss: 0.0063 - fc_trans_loss: 0.0054 - fc_rot_loss: 0.0097\n",
            "Epoch 00015: val_loss did not improve from 0.00667\n",
            "132/132 [==============================] - 216s 1s/step - loss: 0.0063 - fc_trans_loss: 0.0054 - fc_rot_loss: 0.0097 - val_loss: 0.0067 - val_fc_trans_loss: 0.0057 - val_fc_rot_loss: 0.0100\n",
            "Epoch 16/100\n",
            "132/132 [==============================] - ETA: 0s - loss: 0.0057 - fc_trans_loss: 0.0048 - fc_rot_loss: 0.0097\n",
            "Epoch 00016: val_loss improved from 0.00667 to 0.00651, saving model to ./models/016-0.0065.hdf5\n",
            "132/132 [==============================] - 217s 1s/step - loss: 0.0057 - fc_trans_loss: 0.0048 - fc_rot_loss: 0.0097 - val_loss: 0.0065 - val_fc_trans_loss: 0.0055 - val_fc_rot_loss: 0.0097\n",
            "Epoch 17/100\n",
            "132/132 [==============================] - ETA: 0s - loss: 0.0054 - fc_trans_loss: 0.0045 - fc_rot_loss: 0.0095\n",
            "Epoch 00017: val_loss improved from 0.00651 to 0.00590, saving model to ./models/017-0.0059.hdf5\n",
            "132/132 [==============================] - 216s 1s/step - loss: 0.0054 - fc_trans_loss: 0.0045 - fc_rot_loss: 0.0095 - val_loss: 0.0059 - val_fc_trans_loss: 0.0049 - val_fc_rot_loss: 0.0099\n",
            "Epoch 18/100\n",
            "132/132 [==============================] - ETA: 0s - loss: 0.0050 - fc_trans_loss: 0.0041 - fc_rot_loss: 0.0091\n",
            "Epoch 00018: val_loss improved from 0.00590 to 0.00559, saving model to ./models/018-0.0056.hdf5\n",
            "132/132 [==============================] - 216s 1s/step - loss: 0.0050 - fc_trans_loss: 0.0041 - fc_rot_loss: 0.0091 - val_loss: 0.0056 - val_fc_trans_loss: 0.0047 - val_fc_rot_loss: 0.0093\n",
            "Epoch 19/100\n",
            "132/132 [==============================] - ETA: 0s - loss: 0.0049 - fc_trans_loss: 0.0040 - fc_rot_loss: 0.0090\n",
            "Epoch 00019: val_loss did not improve from 0.00559\n",
            "132/132 [==============================] - 216s 1s/step - loss: 0.0049 - fc_trans_loss: 0.0040 - fc_rot_loss: 0.0090 - val_loss: 0.0058 - val_fc_trans_loss: 0.0049 - val_fc_rot_loss: 0.0090\n",
            "Epoch 20/100\n",
            "132/132 [==============================] - ETA: 0s - loss: 0.0047 - fc_trans_loss: 0.0038 - fc_rot_loss: 0.0090\n",
            "Epoch 00020: val_loss improved from 0.00559 to 0.00547, saving model to ./models/020-0.0055.hdf5\n",
            "132/132 [==============================] - 217s 1s/step - loss: 0.0047 - fc_trans_loss: 0.0038 - fc_rot_loss: 0.0090 - val_loss: 0.0055 - val_fc_trans_loss: 0.0045 - val_fc_rot_loss: 0.0095\n",
            "Epoch 21/100\n",
            "132/132 [==============================] - ETA: 0s - loss: 0.0044 - fc_trans_loss: 0.0035 - fc_rot_loss: 0.0085\n",
            "Epoch 00021: val_loss improved from 0.00547 to 0.00534, saving model to ./models/021-0.0053.hdf5\n",
            "132/132 [==============================] - 216s 1s/step - loss: 0.0044 - fc_trans_loss: 0.0035 - fc_rot_loss: 0.0085 - val_loss: 0.0053 - val_fc_trans_loss: 0.0044 - val_fc_rot_loss: 0.0093\n",
            "Epoch 22/100\n",
            "132/132 [==============================] - ETA: 0s - loss: 0.0043 - fc_trans_loss: 0.0035 - fc_rot_loss: 0.0083\n",
            "Epoch 00022: val_loss did not improve from 0.00534\n",
            "132/132 [==============================] - 216s 1s/step - loss: 0.0043 - fc_trans_loss: 0.0035 - fc_rot_loss: 0.0083 - val_loss: 0.0054 - val_fc_trans_loss: 0.0045 - val_fc_rot_loss: 0.0088\n",
            "Epoch 23/100\n",
            "132/132 [==============================] - ETA: 0s - loss: 0.0040 - fc_trans_loss: 0.0032 - fc_rot_loss: 0.0077\n",
            "Epoch 00023: val_loss did not improve from 0.00534\n",
            "132/132 [==============================] - 216s 1s/step - loss: 0.0040 - fc_trans_loss: 0.0032 - fc_rot_loss: 0.0077 - val_loss: 0.0056 - val_fc_trans_loss: 0.0047 - val_fc_rot_loss: 0.0086\n",
            "Epoch 24/100\n",
            "132/132 [==============================] - ETA: 0s - loss: 0.0039 - fc_trans_loss: 0.0031 - fc_rot_loss: 0.0076\n",
            "Epoch 00024: val_loss did not improve from 0.00534\n",
            "132/132 [==============================] - 217s 1s/step - loss: 0.0039 - fc_trans_loss: 0.0031 - fc_rot_loss: 0.0076 - val_loss: 0.0054 - val_fc_trans_loss: 0.0044 - val_fc_rot_loss: 0.0094\n",
            "Epoch 25/100\n",
            "132/132 [==============================] - ETA: 0s - loss: 0.0037 - fc_trans_loss: 0.0030 - fc_rot_loss: 0.0075\n",
            "Epoch 00025: val_loss improved from 0.00534 to 0.00527, saving model to ./models/025-0.0053.hdf5\n",
            "132/132 [==============================] - 218s 1s/step - loss: 0.0037 - fc_trans_loss: 0.0030 - fc_rot_loss: 0.0075 - val_loss: 0.0053 - val_fc_trans_loss: 0.0043 - val_fc_rot_loss: 0.0100\n",
            "Epoch 26/100\n",
            "132/132 [==============================] - ETA: 0s - loss: 0.0035 - fc_trans_loss: 0.0028 - fc_rot_loss: 0.0071\n",
            "Epoch 00026: val_loss improved from 0.00527 to 0.00505, saving model to ./models/026-0.0051.hdf5\n",
            "132/132 [==============================] - 215s 1s/step - loss: 0.0035 - fc_trans_loss: 0.0028 - fc_rot_loss: 0.0071 - val_loss: 0.0051 - val_fc_trans_loss: 0.0042 - val_fc_rot_loss: 0.0084\n",
            "Epoch 27/100\n",
            "132/132 [==============================] - ETA: 0s - loss: 0.0034 - fc_trans_loss: 0.0027 - fc_rot_loss: 0.0070\n",
            "Epoch 00027: val_loss improved from 0.00505 to 0.00489, saving model to ./models/027-0.0049.hdf5\n",
            "132/132 [==============================] - 216s 1s/step - loss: 0.0034 - fc_trans_loss: 0.0027 - fc_rot_loss: 0.0070 - val_loss: 0.0049 - val_fc_trans_loss: 0.0041 - val_fc_rot_loss: 0.0081\n",
            "Epoch 28/100\n",
            "132/132 [==============================] - ETA: 0s - loss: 0.0031 - fc_trans_loss: 0.0025 - fc_rot_loss: 0.0064\n",
            "Epoch 00028: val_loss did not improve from 0.00489\n",
            "132/132 [==============================] - 216s 1s/step - loss: 0.0031 - fc_trans_loss: 0.0025 - fc_rot_loss: 0.0064 - val_loss: 0.0051 - val_fc_trans_loss: 0.0043 - val_fc_rot_loss: 0.0077\n",
            "Epoch 29/100\n",
            "132/132 [==============================] - ETA: 0s - loss: 0.0030 - fc_trans_loss: 0.0024 - fc_rot_loss: 0.0061\n",
            "Epoch 00029: val_loss did not improve from 0.00489\n",
            "132/132 [==============================] - 216s 1s/step - loss: 0.0030 - fc_trans_loss: 0.0024 - fc_rot_loss: 0.0061 - val_loss: 0.0049 - val_fc_trans_loss: 0.0041 - val_fc_rot_loss: 0.0083\n",
            "Epoch 30/100\n",
            "132/132 [==============================] - ETA: 0s - loss: 0.0029 - fc_trans_loss: 0.0023 - fc_rot_loss: 0.0059\n",
            "Epoch 00030: val_loss improved from 0.00489 to 0.00469, saving model to ./models/030-0.0047.hdf5\n",
            "132/132 [==============================] - 217s 1s/step - loss: 0.0029 - fc_trans_loss: 0.0023 - fc_rot_loss: 0.0059 - val_loss: 0.0047 - val_fc_trans_loss: 0.0039 - val_fc_rot_loss: 0.0075\n",
            "Epoch 31/100\n",
            "132/132 [==============================] - ETA: 0s - loss: 0.0027 - fc_trans_loss: 0.0021 - fc_rot_loss: 0.0057\n",
            "Epoch 00031: val_loss did not improve from 0.00469\n",
            "132/132 [==============================] - 216s 1s/step - loss: 0.0027 - fc_trans_loss: 0.0021 - fc_rot_loss: 0.0057 - val_loss: 0.0047 - val_fc_trans_loss: 0.0040 - val_fc_rot_loss: 0.0074\n",
            "Epoch 32/100\n",
            "132/132 [==============================] - ETA: 0s - loss: 0.0026 - fc_trans_loss: 0.0020 - fc_rot_loss: 0.0055\n",
            "Epoch 00032: val_loss did not improve from 0.00469\n",
            "132/132 [==============================] - 216s 1s/step - loss: 0.0026 - fc_trans_loss: 0.0020 - fc_rot_loss: 0.0055 - val_loss: 0.0047 - val_fc_trans_loss: 0.0040 - val_fc_rot_loss: 0.0072\n",
            "Epoch 33/100\n",
            "132/132 [==============================] - ETA: 0s - loss: 0.0024 - fc_trans_loss: 0.0019 - fc_rot_loss: 0.0050\n",
            "Epoch 00033: val_loss did not improve from 0.00469\n",
            "132/132 [==============================] - 216s 1s/step - loss: 0.0024 - fc_trans_loss: 0.0019 - fc_rot_loss: 0.0050 - val_loss: 0.0050 - val_fc_trans_loss: 0.0043 - val_fc_rot_loss: 0.0073\n",
            "Epoch 34/100\n",
            "132/132 [==============================] - ETA: 0s - loss: 0.0023 - fc_trans_loss: 0.0018 - fc_rot_loss: 0.0047\n",
            "Epoch 00034: val_loss improved from 0.00469 to 0.00454, saving model to ./models/034-0.0045.hdf5\n",
            "132/132 [==============================] - 217s 1s/step - loss: 0.0023 - fc_trans_loss: 0.0018 - fc_rot_loss: 0.0047 - val_loss: 0.0045 - val_fc_trans_loss: 0.0039 - val_fc_rot_loss: 0.0068\n",
            "Epoch 35/100\n",
            "132/132 [==============================] - ETA: 0s - loss: 0.0022 - fc_trans_loss: 0.0018 - fc_rot_loss: 0.0044\n",
            "Epoch 00035: val_loss did not improve from 0.00454\n",
            "132/132 [==============================] - 215s 1s/step - loss: 0.0022 - fc_trans_loss: 0.0018 - fc_rot_loss: 0.0044 - val_loss: 0.0046 - val_fc_trans_loss: 0.0039 - val_fc_rot_loss: 0.0071\n",
            "Epoch 36/100\n",
            "132/132 [==============================] - ETA: 0s - loss: 0.0021 - fc_trans_loss: 0.0017 - fc_rot_loss: 0.0043\n",
            "Epoch 00036: val_loss improved from 0.00454 to 0.00454, saving model to ./models/036-0.0045.hdf5\n",
            "132/132 [==============================] - 217s 1s/step - loss: 0.0021 - fc_trans_loss: 0.0017 - fc_rot_loss: 0.0043 - val_loss: 0.0045 - val_fc_trans_loss: 0.0039 - val_fc_rot_loss: 0.0068\n",
            "Epoch 37/100\n",
            "132/132 [==============================] - ETA: 0s - loss: 0.0020 - fc_trans_loss: 0.0015 - fc_rot_loss: 0.0041\n",
            "Epoch 00037: val_loss improved from 0.00454 to 0.00440, saving model to ./models/037-0.0044.hdf5\n",
            "132/132 [==============================] - 216s 1s/step - loss: 0.0020 - fc_trans_loss: 0.0015 - fc_rot_loss: 0.0041 - val_loss: 0.0044 - val_fc_trans_loss: 0.0037 - val_fc_rot_loss: 0.0068\n",
            "Epoch 38/100\n",
            "132/132 [==============================] - ETA: 0s - loss: 0.0019 - fc_trans_loss: 0.0015 - fc_rot_loss: 0.0040\n",
            "Epoch 00038: val_loss did not improve from 0.00440\n",
            "132/132 [==============================] - 216s 1s/step - loss: 0.0019 - fc_trans_loss: 0.0015 - fc_rot_loss: 0.0040 - val_loss: 0.0045 - val_fc_trans_loss: 0.0038 - val_fc_rot_loss: 0.0069\n",
            "Epoch 39/100\n",
            "132/132 [==============================] - ETA: 0s - loss: 0.0018 - fc_trans_loss: 0.0014 - fc_rot_loss: 0.0037\n",
            "Epoch 00039: val_loss did not improve from 0.00440\n",
            "132/132 [==============================] - 216s 1s/step - loss: 0.0018 - fc_trans_loss: 0.0014 - fc_rot_loss: 0.0037 - val_loss: 0.0046 - val_fc_trans_loss: 0.0039 - val_fc_rot_loss: 0.0067\n",
            "Epoch 40/100\n",
            "132/132 [==============================] - ETA: 0s - loss: 0.0017 - fc_trans_loss: 0.0013 - fc_rot_loss: 0.0035\n",
            "Epoch 00040: val_loss did not improve from 0.00440\n",
            "132/132 [==============================] - 216s 1s/step - loss: 0.0017 - fc_trans_loss: 0.0013 - fc_rot_loss: 0.0035 - val_loss: 0.0046 - val_fc_trans_loss: 0.0039 - val_fc_rot_loss: 0.0072\n",
            "Epoch 41/100\n",
            "132/132 [==============================] - ETA: 0s - loss: 0.0016 - fc_trans_loss: 0.0013 - fc_rot_loss: 0.0033\n",
            "Epoch 00041: val_loss improved from 0.00440 to 0.00424, saving model to ./models/041-0.0042.hdf5\n",
            "132/132 [==============================] - 217s 1s/step - loss: 0.0016 - fc_trans_loss: 0.0013 - fc_rot_loss: 0.0033 - val_loss: 0.0042 - val_fc_trans_loss: 0.0036 - val_fc_rot_loss: 0.0065\n",
            "Epoch 42/100\n",
            "132/132 [==============================] - ETA: 0s - loss: 0.0015 - fc_trans_loss: 0.0012 - fc_rot_loss: 0.0032\n",
            "Epoch 00042: val_loss did not improve from 0.00424\n",
            "132/132 [==============================] - 217s 1s/step - loss: 0.0015 - fc_trans_loss: 0.0012 - fc_rot_loss: 0.0032 - val_loss: 0.0045 - val_fc_trans_loss: 0.0038 - val_fc_rot_loss: 0.0068\n",
            "Epoch 43/100\n",
            "132/132 [==============================] - ETA: 0s - loss: 0.0014 - fc_trans_loss: 0.0011 - fc_rot_loss: 0.0029\n",
            "Epoch 00043: val_loss did not improve from 0.00424\n",
            "132/132 [==============================] - 215s 1s/step - loss: 0.0014 - fc_trans_loss: 0.0011 - fc_rot_loss: 0.0029 - val_loss: 0.0045 - val_fc_trans_loss: 0.0038 - val_fc_rot_loss: 0.0065\n",
            "Epoch 44/100\n",
            "132/132 [==============================] - ETA: 0s - loss: 0.0014 - fc_trans_loss: 0.0011 - fc_rot_loss: 0.0030\n",
            "Epoch 00044: val_loss did not improve from 0.00424\n",
            "132/132 [==============================] - 216s 1s/step - loss: 0.0014 - fc_trans_loss: 0.0011 - fc_rot_loss: 0.0030 - val_loss: 0.0045 - val_fc_trans_loss: 0.0038 - val_fc_rot_loss: 0.0071\n",
            "Epoch 45/100\n",
            "132/132 [==============================] - ETA: 0s - loss: 0.0013 - fc_trans_loss: 0.0011 - fc_rot_loss: 0.0026\n",
            "Epoch 00045: val_loss did not improve from 0.00424\n",
            "132/132 [==============================] - 216s 1s/step - loss: 0.0013 - fc_trans_loss: 0.0011 - fc_rot_loss: 0.0026 - val_loss: 0.0043 - val_fc_trans_loss: 0.0036 - val_fc_rot_loss: 0.0070\n",
            "Epoch 46/100\n",
            "132/132 [==============================] - ETA: 0s - loss: 0.0012 - fc_trans_loss: 9.8859e-04 - fc_rot_loss: 0.0024\n",
            "Epoch 00046: val_loss did not improve from 0.00424\n",
            "132/132 [==============================] - 216s 1s/step - loss: 0.0012 - fc_trans_loss: 9.8859e-04 - fc_rot_loss: 0.0024 - val_loss: 0.0044 - val_fc_trans_loss: 0.0037 - val_fc_rot_loss: 0.0065\n",
            "Epoch 47/100\n",
            "132/132 [==============================] - ETA: 0s - loss: 0.0012 - fc_trans_loss: 0.0010 - fc_rot_loss: 0.0023\n",
            "Epoch 00047: val_loss did not improve from 0.00424\n",
            "132/132 [==============================] - 216s 1s/step - loss: 0.0012 - fc_trans_loss: 0.0010 - fc_rot_loss: 0.0023 - val_loss: 0.0045 - val_fc_trans_loss: 0.0038 - val_fc_rot_loss: 0.0071\n",
            "Epoch 48/100\n",
            "132/132 [==============================] - ETA: 0s - loss: 0.0012 - fc_trans_loss: 9.7600e-04 - fc_rot_loss: 0.0023\n",
            "Epoch 00048: val_loss did not improve from 0.00424\n",
            "132/132 [==============================] - 216s 1s/step - loss: 0.0012 - fc_trans_loss: 9.7600e-04 - fc_rot_loss: 0.0023 - val_loss: 0.0043 - val_fc_trans_loss: 0.0037 - val_fc_rot_loss: 0.0067\n",
            "Epoch 49/100\n",
            "132/132 [==============================] - ETA: 0s - loss: 0.0011 - fc_trans_loss: 9.1662e-04 - fc_rot_loss: 0.0021\n",
            "Epoch 00049: val_loss did not improve from 0.00424\n",
            "132/132 [==============================] - 216s 1s/step - loss: 0.0011 - fc_trans_loss: 9.1662e-04 - fc_rot_loss: 0.0021 - val_loss: 0.0043 - val_fc_trans_loss: 0.0037 - val_fc_rot_loss: 0.0067\n",
            "Epoch 50/100\n",
            "132/132 [==============================] - ETA: 0s - loss: 0.0011 - fc_trans_loss: 8.6340e-04 - fc_rot_loss: 0.0021\n",
            "Epoch 00050: val_loss did not improve from 0.00424\n",
            "132/132 [==============================] - 216s 1s/step - loss: 0.0011 - fc_trans_loss: 8.6340e-04 - fc_rot_loss: 0.0021 - val_loss: 0.0044 - val_fc_trans_loss: 0.0037 - val_fc_rot_loss: 0.0067\n",
            "Epoch 51/100\n",
            "132/132 [==============================] - ETA: 0s - loss: 0.0010 - fc_trans_loss: 8.5101e-04 - fc_rot_loss: 0.0018\n",
            "Epoch 00051: val_loss improved from 0.00424 to 0.00423, saving model to ./models/051-0.0042.hdf5\n",
            "132/132 [==============================] - 217s 1s/step - loss: 0.0010 - fc_trans_loss: 8.5101e-04 - fc_rot_loss: 0.0018 - val_loss: 0.0042 - val_fc_trans_loss: 0.0036 - val_fc_rot_loss: 0.0064\n",
            "Epoch 52/100\n",
            "132/132 [==============================] - ETA: 0s - loss: 0.0010 - fc_trans_loss: 8.4295e-04 - fc_rot_loss: 0.0019\n",
            "Epoch 00052: val_loss did not improve from 0.00423\n",
            "132/132 [==============================] - 216s 1s/step - loss: 0.0010 - fc_trans_loss: 8.4295e-04 - fc_rot_loss: 0.0019 - val_loss: 0.0044 - val_fc_trans_loss: 0.0037 - val_fc_rot_loss: 0.0071\n",
            "Epoch 53/100\n",
            "132/132 [==============================] - ETA: 0s - loss: 0.0010 - fc_trans_loss: 8.3363e-04 - fc_rot_loss: 0.0019\n",
            "Epoch 00053: val_loss did not improve from 0.00423\n",
            "132/132 [==============================] - 216s 1s/step - loss: 0.0010 - fc_trans_loss: 8.3363e-04 - fc_rot_loss: 0.0019 - val_loss: 0.0045 - val_fc_trans_loss: 0.0038 - val_fc_rot_loss: 0.0071\n",
            "Epoch 54/100\n",
            "132/132 [==============================] - ETA: 0s - loss: 0.0010 - fc_trans_loss: 8.4048e-04 - fc_rot_loss: 0.0018\n",
            "Epoch 00054: val_loss did not improve from 0.00423\n",
            "132/132 [==============================] - 216s 1s/step - loss: 0.0010 - fc_trans_loss: 8.4048e-04 - fc_rot_loss: 0.0018 - val_loss: 0.0044 - val_fc_trans_loss: 0.0037 - val_fc_rot_loss: 0.0072\n",
            "Epoch 55/100\n",
            "132/132 [==============================] - ETA: 0s - loss: 9.3956e-04 - fc_trans_loss: 7.7418e-04 - fc_rot_loss: 0.0017\n",
            "Epoch 00055: val_loss did not improve from 0.00423\n",
            "132/132 [==============================] - 217s 1s/step - loss: 9.3956e-04 - fc_trans_loss: 7.7418e-04 - fc_rot_loss: 0.0017 - val_loss: 0.0043 - val_fc_trans_loss: 0.0036 - val_fc_rot_loss: 0.0071\n",
            "Epoch 56/100\n",
            "132/132 [==============================] - ETA: 0s - loss: 9.1856e-04 - fc_trans_loss: 7.5993e-04 - fc_rot_loss: 0.0016\n",
            "Epoch 00056: val_loss did not improve from 0.00423\n",
            "132/132 [==============================] - 215s 1s/step - loss: 9.1856e-04 - fc_trans_loss: 7.5993e-04 - fc_rot_loss: 0.0016 - val_loss: 0.0044 - val_fc_trans_loss: 0.0037 - val_fc_rot_loss: 0.0067\n",
            "Epoch 57/100\n",
            "132/132 [==============================] - ETA: 0s - loss: 8.7204e-04 - fc_trans_loss: 7.2604e-04 - fc_rot_loss: 0.0015\n",
            "Epoch 00057: val_loss did not improve from 0.00423\n",
            "132/132 [==============================] - 216s 1s/step - loss: 8.7204e-04 - fc_trans_loss: 7.2604e-04 - fc_rot_loss: 0.0015 - val_loss: 0.0043 - val_fc_trans_loss: 0.0036 - val_fc_rot_loss: 0.0065\n",
            "Epoch 58/100\n",
            "132/132 [==============================] - ETA: 0s - loss: 8.1837e-04 - fc_trans_loss: 6.7741e-04 - fc_rot_loss: 0.0014\n",
            "Epoch 00058: val_loss did not improve from 0.00423\n",
            "132/132 [==============================] - 216s 1s/step - loss: 8.1837e-04 - fc_trans_loss: 6.7741e-04 - fc_rot_loss: 0.0014 - val_loss: 0.0043 - val_fc_trans_loss: 0.0037 - val_fc_rot_loss: 0.0066\n",
            "Epoch 59/100\n",
            "132/132 [==============================] - ETA: 0s - loss: 8.2423e-04 - fc_trans_loss: 6.7820e-04 - fc_rot_loss: 0.0015\n",
            "Epoch 00059: val_loss did not improve from 0.00423\n",
            "132/132 [==============================] - 216s 1s/step - loss: 8.2423e-04 - fc_trans_loss: 6.7820e-04 - fc_rot_loss: 0.0015 - val_loss: 0.0045 - val_fc_trans_loss: 0.0038 - val_fc_rot_loss: 0.0068\n",
            "Epoch 60/100\n",
            "132/132 [==============================] - ETA: 0s - loss: 7.9545e-04 - fc_trans_loss: 6.5802e-04 - fc_rot_loss: 0.0014\n",
            "Epoch 00060: val_loss did not improve from 0.00423\n",
            "132/132 [==============================] - 216s 1s/step - loss: 7.9545e-04 - fc_trans_loss: 6.5802e-04 - fc_rot_loss: 0.0014 - val_loss: 0.0045 - val_fc_trans_loss: 0.0038 - val_fc_rot_loss: 0.0069\n",
            "Epoch 61/100\n",
            "132/132 [==============================] - ETA: 0s - loss: 7.7369e-04 - fc_trans_loss: 6.3194e-04 - fc_rot_loss: 0.0014\n",
            "Epoch 00061: val_loss did not improve from 0.00423\n",
            "132/132 [==============================] - 216s 1s/step - loss: 7.7369e-04 - fc_trans_loss: 6.3194e-04 - fc_rot_loss: 0.0014 - val_loss: 0.0043 - val_fc_trans_loss: 0.0036 - val_fc_rot_loss: 0.0073\n",
            "Epoch 62/100\n",
            "132/132 [==============================] - ETA: 0s - loss: 7.5466e-04 - fc_trans_loss: 6.2675e-04 - fc_rot_loss: 0.0013\n",
            "Epoch 00062: val_loss improved from 0.00423 to 0.00422, saving model to ./models/062-0.0042.hdf5\n",
            "132/132 [==============================] - 217s 1s/step - loss: 7.5466e-04 - fc_trans_loss: 6.2675e-04 - fc_rot_loss: 0.0013 - val_loss: 0.0042 - val_fc_trans_loss: 0.0035 - val_fc_rot_loss: 0.0067\n",
            "Epoch 63/100\n",
            "132/132 [==============================] - ETA: 0s - loss: 7.2319e-04 - fc_trans_loss: 6.0072e-04 - fc_rot_loss: 0.0012\n",
            "Epoch 00063: val_loss did not improve from 0.00422\n",
            "132/132 [==============================] - 216s 1s/step - loss: 7.2319e-04 - fc_trans_loss: 6.0072e-04 - fc_rot_loss: 0.0012 - val_loss: 0.0046 - val_fc_trans_loss: 0.0039 - val_fc_rot_loss: 0.0071\n",
            "Epoch 64/100\n",
            "132/132 [==============================] - ETA: 0s - loss: 6.9502e-04 - fc_trans_loss: 5.7945e-04 - fc_rot_loss: 0.0012\n",
            "Epoch 00064: val_loss did not improve from 0.00422\n",
            "132/132 [==============================] - 216s 1s/step - loss: 6.9502e-04 - fc_trans_loss: 5.7945e-04 - fc_rot_loss: 0.0012 - val_loss: 0.0043 - val_fc_trans_loss: 0.0036 - val_fc_rot_loss: 0.0067\n",
            "Epoch 65/100\n",
            "132/132 [==============================] - ETA: 0s - loss: 6.6065e-04 - fc_trans_loss: 5.4233e-04 - fc_rot_loss: 0.0012\n",
            "Epoch 00065: val_loss did not improve from 0.00422\n",
            "132/132 [==============================] - 216s 1s/step - loss: 6.6065e-04 - fc_trans_loss: 5.4233e-04 - fc_rot_loss: 0.0012 - val_loss: 0.0043 - val_fc_trans_loss: 0.0036 - val_fc_rot_loss: 0.0070\n",
            "Epoch 66/100\n",
            "132/132 [==============================] - ETA: 0s - loss: 7.0227e-04 - fc_trans_loss: 5.8232e-04 - fc_rot_loss: 0.0012\n",
            "Epoch 00066: val_loss improved from 0.00422 to 0.00416, saving model to ./models/066-0.0042.hdf5\n",
            "132/132 [==============================] - 217s 1s/step - loss: 7.0227e-04 - fc_trans_loss: 5.8232e-04 - fc_rot_loss: 0.0012 - val_loss: 0.0042 - val_fc_trans_loss: 0.0035 - val_fc_rot_loss: 0.0070\n",
            "Epoch 67/100\n",
            "132/132 [==============================] - ETA: 0s - loss: 6.3333e-04 - fc_trans_loss: 5.2464e-04 - fc_rot_loss: 0.0011\n",
            "Epoch 00067: val_loss did not improve from 0.00416\n",
            "132/132 [==============================] - 216s 1s/step - loss: 6.3333e-04 - fc_trans_loss: 5.2464e-04 - fc_rot_loss: 0.0011 - val_loss: 0.0044 - val_fc_trans_loss: 0.0037 - val_fc_rot_loss: 0.0068\n",
            "Epoch 68/100\n",
            "132/132 [==============================] - ETA: 0s - loss: 5.8667e-04 - fc_trans_loss: 4.8472e-04 - fc_rot_loss: 0.0010\n",
            "Epoch 00068: val_loss did not improve from 0.00416\n",
            "132/132 [==============================] - 216s 1s/step - loss: 5.8667e-04 - fc_trans_loss: 4.8472e-04 - fc_rot_loss: 0.0010 - val_loss: 0.0043 - val_fc_trans_loss: 0.0036 - val_fc_rot_loss: 0.0069\n",
            "Epoch 69/100\n",
            "132/132 [==============================] - ETA: 0s - loss: 5.6700e-04 - fc_trans_loss: 4.6869e-04 - fc_rot_loss: 9.8314e-04\n",
            "Epoch 00069: val_loss did not improve from 0.00416\n",
            "132/132 [==============================] - 216s 1s/step - loss: 5.6700e-04 - fc_trans_loss: 4.6869e-04 - fc_rot_loss: 9.8314e-04 - val_loss: 0.0045 - val_fc_trans_loss: 0.0038 - val_fc_rot_loss: 0.0067\n",
            "Epoch 70/100\n",
            "132/132 [==============================] - ETA: 0s - loss: 5.8781e-04 - fc_trans_loss: 4.8645e-04 - fc_rot_loss: 0.0010\n",
            "Epoch 00070: val_loss did not improve from 0.00416\n",
            "132/132 [==============================] - 216s 1s/step - loss: 5.8781e-04 - fc_trans_loss: 4.8645e-04 - fc_rot_loss: 0.0010 - val_loss: 0.0043 - val_fc_trans_loss: 0.0036 - val_fc_rot_loss: 0.0065\n",
            "Epoch 71/100\n",
            "132/132 [==============================] - ETA: 0s - loss: 5.7017e-04 - fc_trans_loss: 4.7162e-04 - fc_rot_loss: 9.8544e-04\n",
            "Epoch 00071: val_loss did not improve from 0.00416\n",
            "132/132 [==============================] - 216s 1s/step - loss: 5.7017e-04 - fc_trans_loss: 4.7162e-04 - fc_rot_loss: 9.8544e-04 - val_loss: 0.0043 - val_fc_trans_loss: 0.0036 - val_fc_rot_loss: 0.0068\n",
            "Epoch 72/100\n",
            "132/132 [==============================] - ETA: 0s - loss: 5.8694e-04 - fc_trans_loss: 4.8503e-04 - fc_rot_loss: 0.0010\n",
            "Epoch 00072: val_loss did not improve from 0.00416\n",
            "132/132 [==============================] - 216s 1s/step - loss: 5.8694e-04 - fc_trans_loss: 4.8503e-04 - fc_rot_loss: 0.0010 - val_loss: 0.0043 - val_fc_trans_loss: 0.0037 - val_fc_rot_loss: 0.0066\n",
            "Epoch 73/100\n",
            "132/132 [==============================] - ETA: 0s - loss: 6.0083e-04 - fc_trans_loss: 4.9888e-04 - fc_rot_loss: 0.0010\n",
            "Epoch 00073: val_loss did not improve from 0.00416\n",
            "132/132 [==============================] - 216s 1s/step - loss: 6.0083e-04 - fc_trans_loss: 4.9888e-04 - fc_rot_loss: 0.0010 - val_loss: 0.0044 - val_fc_trans_loss: 0.0037 - val_fc_rot_loss: 0.0066\n",
            "Epoch 74/100\n",
            "132/132 [==============================] - ETA: 0s - loss: 5.7919e-04 - fc_trans_loss: 4.7605e-04 - fc_rot_loss: 0.0010\n",
            "Epoch 00074: val_loss did not improve from 0.00416\n",
            "132/132 [==============================] - 216s 1s/step - loss: 5.7919e-04 - fc_trans_loss: 4.7605e-04 - fc_rot_loss: 0.0010 - val_loss: 0.0043 - val_fc_trans_loss: 0.0037 - val_fc_rot_loss: 0.0068\n",
            "Epoch 75/100\n",
            "132/132 [==============================] - ETA: 0s - loss: 5.5941e-04 - fc_trans_loss: 4.6733e-04 - fc_rot_loss: 9.2075e-04\n",
            "Epoch 00075: val_loss improved from 0.00416 to 0.00407, saving model to ./models/075-0.0041.hdf5\n",
            "132/132 [==============================] - 217s 1s/step - loss: 5.5941e-04 - fc_trans_loss: 4.6733e-04 - fc_rot_loss: 9.2075e-04 - val_loss: 0.0041 - val_fc_trans_loss: 0.0034 - val_fc_rot_loss: 0.0067\n",
            "Epoch 76/100\n",
            "132/132 [==============================] - ETA: 0s - loss: 5.1468e-04 - fc_trans_loss: 4.2435e-04 - fc_rot_loss: 9.0328e-04\n",
            "Epoch 00076: val_loss improved from 0.00407 to 0.00396, saving model to ./models/076-0.0040.hdf5\n",
            "132/132 [==============================] - 218s 1s/step - loss: 5.1468e-04 - fc_trans_loss: 4.2435e-04 - fc_rot_loss: 9.0328e-04 - val_loss: 0.0040 - val_fc_trans_loss: 0.0033 - val_fc_rot_loss: 0.0069\n",
            "Epoch 77/100\n",
            "132/132 [==============================] - ETA: 0s - loss: 5.0606e-04 - fc_trans_loss: 4.1405e-04 - fc_rot_loss: 9.2013e-04\n",
            "Epoch 00077: val_loss did not improve from 0.00396\n",
            "132/132 [==============================] - 214s 1s/step - loss: 5.0606e-04 - fc_trans_loss: 4.1405e-04 - fc_rot_loss: 9.2013e-04 - val_loss: 0.0043 - val_fc_trans_loss: 0.0036 - val_fc_rot_loss: 0.0067\n",
            "Epoch 78/100\n",
            "132/132 [==============================] - ETA: 0s - loss: 4.7736e-04 - fc_trans_loss: 3.9145e-04 - fc_rot_loss: 8.5917e-04\n",
            "Epoch 00078: val_loss did not improve from 0.00396\n",
            "132/132 [==============================] - 216s 1s/step - loss: 4.7736e-04 - fc_trans_loss: 3.9145e-04 - fc_rot_loss: 8.5917e-04 - val_loss: 0.0041 - val_fc_trans_loss: 0.0034 - val_fc_rot_loss: 0.0069\n",
            "Epoch 79/100\n",
            "132/132 [==============================] - ETA: 0s - loss: 4.8204e-04 - fc_trans_loss: 3.9007e-04 - fc_rot_loss: 9.1973e-04\n",
            "Epoch 00079: val_loss improved from 0.00396 to 0.00391, saving model to ./models/079-0.0039.hdf5\n",
            "132/132 [==============================] - 217s 1s/step - loss: 4.8204e-04 - fc_trans_loss: 3.9007e-04 - fc_rot_loss: 9.1973e-04 - val_loss: 0.0039 - val_fc_trans_loss: 0.0033 - val_fc_rot_loss: 0.0063\n",
            "Epoch 80/100\n",
            "132/132 [==============================] - ETA: 0s - loss: 4.3647e-04 - fc_trans_loss: 3.5969e-04 - fc_rot_loss: 7.6780e-04\n",
            "Epoch 00080: val_loss did not improve from 0.00391\n",
            "132/132 [==============================] - 216s 1s/step - loss: 4.3647e-04 - fc_trans_loss: 3.5969e-04 - fc_rot_loss: 7.6780e-04 - val_loss: 0.0042 - val_fc_trans_loss: 0.0035 - val_fc_rot_loss: 0.0069\n",
            "Epoch 81/100\n",
            "132/132 [==============================] - ETA: 0s - loss: 4.5491e-04 - fc_trans_loss: 3.7285e-04 - fc_rot_loss: 8.2063e-04\n",
            "Epoch 00081: val_loss did not improve from 0.00391\n",
            "132/132 [==============================] - 216s 1s/step - loss: 4.5491e-04 - fc_trans_loss: 3.7285e-04 - fc_rot_loss: 8.2063e-04 - val_loss: 0.0042 - val_fc_trans_loss: 0.0035 - val_fc_rot_loss: 0.0067\n",
            "Epoch 82/100\n",
            "132/132 [==============================] - ETA: 0s - loss: 4.7851e-04 - fc_trans_loss: 3.9578e-04 - fc_rot_loss: 8.2728e-04\n",
            "Epoch 00082: val_loss did not improve from 0.00391\n",
            "132/132 [==============================] - 216s 1s/step - loss: 4.7851e-04 - fc_trans_loss: 3.9578e-04 - fc_rot_loss: 8.2728e-04 - val_loss: 0.0042 - val_fc_trans_loss: 0.0035 - val_fc_rot_loss: 0.0070\n",
            "Epoch 83/100\n",
            "132/132 [==============================] - ETA: 0s - loss: 4.8687e-04 - fc_trans_loss: 4.0432e-04 - fc_rot_loss: 8.2545e-04\n",
            "Epoch 00083: val_loss did not improve from 0.00391\n",
            "132/132 [==============================] - 216s 1s/step - loss: 4.8687e-04 - fc_trans_loss: 4.0432e-04 - fc_rot_loss: 8.2545e-04 - val_loss: 0.0041 - val_fc_trans_loss: 0.0035 - val_fc_rot_loss: 0.0066\n",
            "Epoch 84/100\n",
            "132/132 [==============================] - ETA: 0s - loss: 4.6913e-04 - fc_trans_loss: 3.9215e-04 - fc_rot_loss: 7.6982e-04\n",
            "Epoch 00084: val_loss did not improve from 0.00391\n",
            "132/132 [==============================] - 216s 1s/step - loss: 4.6913e-04 - fc_trans_loss: 3.9215e-04 - fc_rot_loss: 7.6982e-04 - val_loss: 0.0043 - val_fc_trans_loss: 0.0036 - val_fc_rot_loss: 0.0066\n",
            "Epoch 85/100\n",
            "132/132 [==============================] - ETA: 0s - loss: 4.4143e-04 - fc_trans_loss: 3.6389e-04 - fc_rot_loss: 7.7530e-04\n",
            "Epoch 00085: val_loss did not improve from 0.00391\n",
            "132/132 [==============================] - 216s 1s/step - loss: 4.4143e-04 - fc_trans_loss: 3.6389e-04 - fc_rot_loss: 7.7530e-04 - val_loss: 0.0041 - val_fc_trans_loss: 0.0034 - val_fc_rot_loss: 0.0067\n",
            "Epoch 86/100\n",
            "132/132 [==============================] - ETA: 0s - loss: 4.2088e-04 - fc_trans_loss: 3.4429e-04 - fc_rot_loss: 7.6586e-04\n",
            "Epoch 00086: val_loss did not improve from 0.00391\n",
            "132/132 [==============================] - 216s 1s/step - loss: 4.2088e-04 - fc_trans_loss: 3.4429e-04 - fc_rot_loss: 7.6586e-04 - val_loss: 0.0042 - val_fc_trans_loss: 0.0035 - val_fc_rot_loss: 0.0067\n",
            "Epoch 87/100\n",
            "132/132 [==============================] - ETA: 0s - loss: 3.8389e-04 - fc_trans_loss: 3.1180e-04 - fc_rot_loss: 7.2084e-04\n",
            "Epoch 00087: val_loss did not improve from 0.00391\n",
            "132/132 [==============================] - 216s 1s/step - loss: 3.8389e-04 - fc_trans_loss: 3.1180e-04 - fc_rot_loss: 7.2084e-04 - val_loss: 0.0042 - val_fc_trans_loss: 0.0035 - val_fc_rot_loss: 0.0067\n",
            "Epoch 88/100\n",
            "132/132 [==============================] - ETA: 0s - loss: 3.8665e-04 - fc_trans_loss: 3.1120e-04 - fc_rot_loss: 7.5457e-04\n",
            "Epoch 00088: val_loss did not improve from 0.00391\n",
            "132/132 [==============================] - 216s 1s/step - loss: 3.8665e-04 - fc_trans_loss: 3.1120e-04 - fc_rot_loss: 7.5457e-04 - val_loss: 0.0042 - val_fc_trans_loss: 0.0035 - val_fc_rot_loss: 0.0069\n",
            "Epoch 89/100\n",
            "132/132 [==============================] - ETA: 0s - loss: 3.8922e-04 - fc_trans_loss: 3.1914e-04 - fc_rot_loss: 7.0079e-04\n",
            "Epoch 00089: val_loss did not improve from 0.00391\n",
            "132/132 [==============================] - 216s 1s/step - loss: 3.8922e-04 - fc_trans_loss: 3.1914e-04 - fc_rot_loss: 7.0079e-04 - val_loss: 0.0041 - val_fc_trans_loss: 0.0034 - val_fc_rot_loss: 0.0067\n",
            "Epoch 90/100\n",
            "132/132 [==============================] - ETA: 0s - loss: 4.1741e-04 - fc_trans_loss: 3.4497e-04 - fc_rot_loss: 7.2445e-04\n",
            "Epoch 00090: val_loss did not improve from 0.00391\n",
            "132/132 [==============================] - 216s 1s/step - loss: 4.1741e-04 - fc_trans_loss: 3.4497e-04 - fc_rot_loss: 7.2445e-04 - val_loss: 0.0042 - val_fc_trans_loss: 0.0036 - val_fc_rot_loss: 0.0065\n",
            "Epoch 91/100\n",
            "132/132 [==============================] - ETA: 0s - loss: 4.0825e-04 - fc_trans_loss: 3.3927e-04 - fc_rot_loss: 6.8978e-04\n",
            "Epoch 00091: val_loss did not improve from 0.00391\n",
            "132/132 [==============================] - 216s 1s/step - loss: 4.0825e-04 - fc_trans_loss: 3.3927e-04 - fc_rot_loss: 6.8978e-04 - val_loss: 0.0041 - val_fc_trans_loss: 0.0034 - val_fc_rot_loss: 0.0070\n",
            "Epoch 92/100\n",
            "132/132 [==============================] - ETA: 0s - loss: 4.0157e-04 - fc_trans_loss: 3.3150e-04 - fc_rot_loss: 7.0074e-04\n",
            "Epoch 00092: val_loss did not improve from 0.00391\n",
            "132/132 [==============================] - 216s 1s/step - loss: 4.0157e-04 - fc_trans_loss: 3.3150e-04 - fc_rot_loss: 7.0074e-04 - val_loss: 0.0042 - val_fc_trans_loss: 0.0035 - val_fc_rot_loss: 0.0070\n",
            "Epoch 93/100\n",
            "132/132 [==============================] - ETA: 0s - loss: 3.7498e-04 - fc_trans_loss: 3.0704e-04 - fc_rot_loss: 6.7938e-04\n",
            "Epoch 00093: val_loss did not improve from 0.00391\n",
            "132/132 [==============================] - 216s 1s/step - loss: 3.7498e-04 - fc_trans_loss: 3.0704e-04 - fc_rot_loss: 6.7938e-04 - val_loss: 0.0042 - val_fc_trans_loss: 0.0035 - val_fc_rot_loss: 0.0070\n",
            "Epoch 94/100\n",
            "132/132 [==============================] - ETA: 0s - loss: 3.7827e-04 - fc_trans_loss: 3.1007e-04 - fc_rot_loss: 6.8205e-04\n",
            "Epoch 00094: val_loss did not improve from 0.00391\n",
            "132/132 [==============================] - 216s 1s/step - loss: 3.7827e-04 - fc_trans_loss: 3.1007e-04 - fc_rot_loss: 6.8205e-04 - val_loss: 0.0041 - val_fc_trans_loss: 0.0034 - val_fc_rot_loss: 0.0065\n",
            "Epoch 95/100\n",
            "132/132 [==============================] - ETA: 0s - loss: 3.6089e-04 - fc_trans_loss: 2.9691e-04 - fc_rot_loss: 6.3986e-04\n",
            "Epoch 00095: val_loss did not improve from 0.00391\n",
            "132/132 [==============================] - 216s 1s/step - loss: 3.6089e-04 - fc_trans_loss: 2.9691e-04 - fc_rot_loss: 6.3986e-04 - val_loss: 0.0041 - val_fc_trans_loss: 0.0034 - val_fc_rot_loss: 0.0065\n",
            "Epoch 96/100\n",
            "132/132 [==============================] - ETA: 0s - loss: 3.6038e-04 - fc_trans_loss: 2.9044e-04 - fc_rot_loss: 6.9936e-04\n",
            "Epoch 00096: val_loss did not improve from 0.00391\n",
            "132/132 [==============================] - 216s 1s/step - loss: 3.6038e-04 - fc_trans_loss: 2.9044e-04 - fc_rot_loss: 6.9936e-04 - val_loss: 0.0042 - val_fc_trans_loss: 0.0035 - val_fc_rot_loss: 0.0068\n",
            "Epoch 97/100\n",
            "132/132 [==============================] - ETA: 0s - loss: 3.5987e-04 - fc_trans_loss: 2.9754e-04 - fc_rot_loss: 6.2325e-04\n",
            "Epoch 00097: val_loss did not improve from 0.00391\n",
            "132/132 [==============================] - 216s 1s/step - loss: 3.5987e-04 - fc_trans_loss: 2.9754e-04 - fc_rot_loss: 6.2325e-04 - val_loss: 0.0040 - val_fc_trans_loss: 0.0033 - val_fc_rot_loss: 0.0065\n",
            "Epoch 98/100\n",
            "132/132 [==============================] - ETA: 0s - loss: 3.6269e-04 - fc_trans_loss: 2.9904e-04 - fc_rot_loss: 6.3654e-04\n",
            "Epoch 00098: val_loss did not improve from 0.00391\n",
            "132/132 [==============================] - 216s 1s/step - loss: 3.6269e-04 - fc_trans_loss: 2.9904e-04 - fc_rot_loss: 6.3654e-04 - val_loss: 0.0041 - val_fc_trans_loss: 0.0035 - val_fc_rot_loss: 0.0066\n",
            "Epoch 99/100\n",
            "132/132 [==============================] - ETA: 0s - loss: 3.4818e-04 - fc_trans_loss: 2.8791e-04 - fc_rot_loss: 6.0268e-04\n",
            "Epoch 00099: val_loss did not improve from 0.00391\n",
            "132/132 [==============================] - 216s 1s/step - loss: 3.4818e-04 - fc_trans_loss: 2.8791e-04 - fc_rot_loss: 6.0268e-04 - val_loss: 0.0040 - val_fc_trans_loss: 0.0034 - val_fc_rot_loss: 0.0066\n",
            "Epoch 100/100\n",
            "132/132 [==============================] - ETA: 0s - loss: 3.2730e-04 - fc_trans_loss: 2.7089e-04 - fc_rot_loss: 5.6407e-04\n",
            "Epoch 00100: val_loss did not improve from 0.00391\n",
            "132/132 [==============================] - 216s 1s/step - loss: 3.2730e-04 - fc_trans_loss: 2.7089e-04 - fc_rot_loss: 5.6407e-04 - val_loss: 0.0039 - val_fc_trans_loss: 0.0033 - val_fc_rot_loss: 0.0067\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-9-fc7189bbbd22>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0;31m# history_model = model.fit(X_train, y_train, validation_data=[X_val, y_val], epochs=200, batch_size=8, callbacks=[lrate, checkpointer, tensorboard_callback], verbose=1)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcheckpointer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensorboard_callback\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 42\u001b[0;31m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistory_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhistory_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'pickle' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W41_oXRB5EK-",
        "outputId": "ef03b8b9-a0bf-4d72-97b4-81f8f60cb52e"
      },
      "source": [
        "%tensorboard --logdir logs"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "UsageError: Line magic function `%tensorboard` not found.\n"
          ]
        }
      ]
    }
  ]
}